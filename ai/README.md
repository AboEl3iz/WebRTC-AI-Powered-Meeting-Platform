<![CDATA[# ðŸ§  AI Service â€” Meeting Intelligence Pipeline

> An intelligent meeting processing service built with **Python**, **FastAPI**, **LangGraph**, **Whisper**, and **LLMs**, featuring automated transcription, summarization, event extraction, and distribution to **Notion** and **Google Calendar** via an MCP (Model Context Protocol) layer.

---

## ðŸ“– Overview

The AI service is an event-driven microservice that automatically processes meeting recordings. When a recording is completed and uploaded to MinIO, the backend publishes a `recording.completed` event to RabbitMQ. The AI service consumes this event, downloads the recording, and runs it through a multi-stage LangGraph pipeline that extracts audio, transcribes it, refines the transcript, generates a summary, extracts calendar events, and distributes the results to each participant's connected services (Notion, Google Calendar).

---

## âœ¨ Features

### ðŸŽ™ï¸ Audio Processing
- **Audio Extraction** â€” Extracts the audio track from the composite MP4 recording using FFmpeg.
- **Audio Cleaning** â€” Applies noise reduction and audio normalization to improve transcription accuracy.

### ðŸ“ Transcription
- **Whisper-Based Transcription** â€” Uses the Whisper speech-to-text model (via `faster-whisper` and `whisperx`) for high-accuracy, multi-language transcription.
- **Segment-Level Output** â€” Produces timestamped transcript segments for precise alignment.
- **Egyptian Arabic Support** â€” Fine-tuned model support (`nabbra/whisper-medium-egyptian-arabic`) for Arabic dialect transcription.

### âœï¸ Transcript Refinement
- **LLM-Powered Refinement** â€” Uses a large language model to clean up transcription artifacts, fix grammar, and improve readability while preserving the original meaning.

### ðŸ“‹ Meeting Summarization
- **Intelligent Summarization** â€” Generates concise, structured meeting summaries using LLMs, capturing key discussion points, decisions, and action items.

### ðŸ“… Event Extraction
- **Heuristic-Based Gating** â€” Before invoking the LLM, a fast heuristic check determines if the transcript likely contains schedulable events (to avoid unnecessary API calls).
- **LLM Event Extraction** â€” When events are detected, the LLM extracts structured calendar event data (title, date, time, description) from the transcript.
- **Conditional Pipeline Edge** â€” LangGraph's conditional edges route the pipeline to skip event extraction when no events are detected.

### ðŸ”„ Distribution (MCP â€” Model Context Protocol)
- **Per-Participant Distribution** â€” Meeting outputs are distributed individually to each participant based on their connected integrations.
- **Notion Integration** â€” Automatically creates a Notion page with the meeting summary, full transcript, and extracted events in the participant's workspace.
- **Google Calendar Integration** â€” Creates calendar events in the participant's Google Calendar for any scheduled follow-ups extracted from the meeting.
- **Error Isolation** â€” If one participant's integration fails, it doesn't affect other participants' distributions.

### ðŸ‡ Event-Driven Architecture
- **RabbitMQ Consumer** â€” Listens on the `recording.completed` queue for new recording events.
- **Automatic Pipeline Trigger** â€” Each event automatically downloads the recording from MinIO and triggers the full pipeline.
- **Fallback Mode** â€” If RabbitMQ is unavailable, the service still runs with a manual `/process` REST endpoint.

### ðŸ”Œ LLM Provider Flexibility
- **Provider Factory Pattern** â€” Supports multiple LLM backends through a factory pattern.
- **OpenAI** â€” Integration with OpenAI's GPT models.
- **Google GenAI** â€” Integration with Google's Gemini models.
- **Ollama** â€” Support for locally hosted models via Ollama for offline/privacy-sensitive deployments.

### ðŸ“¡ REST API
- **Manual Processing Endpoint** â€” `POST /api/v1/process` allows manual file upload and pipeline execution for testing and development.
- **MCP Distribution Endpoint** â€” `POST /api/v1/mcp/distribute` allows manual triggering of the distribution step with pre-computed meeting data.

---

## ðŸ—ï¸ Tech Stack

| Technology | Purpose |
|---|---|
| **Python 3.12+** | Runtime |
| **FastAPI** | REST API framework |
| **LangGraph** | Pipeline orchestration (DAG-based state machine) |
| **LangChain** | LLM abstraction layer |
| **Whisper / WhisperX** | Speech-to-text transcription |
| **faster-whisper** | Optimized Whisper inference |
| **OpenAI SDK** | GPT model integration |
| **Google GenAI** | Gemini model integration |
| **aio-pika** | Async RabbitMQ client |
| **boto3** | MinIO/S3 file download |
| **Notion Client** | Notion API integration |
| **Google Calendar API** | Calendar event creation |
| **FFmpeg (ffmpeg-python)** | Audio extraction & processing |
| **Pydantic** | Data validation & models |

---

## ðŸ“‚ Project Structure

```
ai/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ audio/
â”‚       â”‚   â”œâ”€â”€ extractor.py            # FFmpeg audio extraction from video
â”‚       â”‚   â””â”€â”€ cleaner.py              # Audio noise reduction & normalization
â”‚       â”œâ”€â”€ transcription/
â”‚       â”‚   â”œâ”€â”€ whisper_service.py       # Whisper/WhisperX transcription engine
â”‚       â”‚   â””â”€â”€ early_patch.py          # Runtime patches for model loading
â”‚       â”œâ”€â”€ llm/
â”‚       â”‚   â”œâ”€â”€ base.py                 # Abstract LLM interface
â”‚       â”‚   â”œâ”€â”€ factory.py              # LLM provider factory
â”‚       â”‚   â””â”€â”€ providers/
â”‚       â”‚       â”œâ”€â”€ openai_llm.py       # OpenAI GPT provider
â”‚       â”‚       â”œâ”€â”€ google_llm.py       # Google Gemini provider
â”‚       â”‚       â””â”€â”€ ollama_llm.py       # Ollama local model provider
â”‚       â”œâ”€â”€ ai/
â”‚       â”‚   â”œâ”€â”€ summarizer.py           # Meeting summarization logic
â”‚       â”‚   â””â”€â”€ event_extractor.py      # Calendar event extraction
â”‚       â”œâ”€â”€ pipelines/
â”‚       â”‚   â”œâ”€â”€ state.py                # LangGraph pipeline state definition
â”‚       â”‚   â”œâ”€â”€ graph.py                # Pipeline DAG construction
â”‚       â”‚   â””â”€â”€ nodes/
â”‚       â”‚       â”œâ”€â”€ extract_audio.py    # Node: extract audio from video
â”‚       â”‚       â”œâ”€â”€ clean_audio.py      # Node: clean/normalize audio
â”‚       â”‚       â”œâ”€â”€ transcribe.py       # Node: run Whisper transcription
â”‚       â”‚       â”œâ”€â”€ refine_transcript.py# Node: LLM transcript refinement
â”‚       â”‚       â”œâ”€â”€ summarize.py        # Node: generate meeting summary
â”‚       â”‚       â”œâ”€â”€ extract_events.py   # Node: extract calendar events
â”‚       â”‚       â””â”€â”€ distribute.py       # Node: distribute to integrations
â”‚       â”œâ”€â”€ messaging/
â”‚       â”‚   â”œâ”€â”€ rabbitmq.py             # RabbitMQ connection management
â”‚       â”‚   â””â”€â”€ consumer.py            # Event consumer & pipeline trigger
â”‚       â”œâ”€â”€ storage/
â”‚       â”‚   â””â”€â”€ minio_client.py         # MinIO download client
â”‚       â””â”€â”€ logging_config.py           # Structured logging setup
â”œâ”€â”€ mcp/
â”‚   â”œâ”€â”€ models.py                       # MCP data models (MeetingData, Participant)
â”‚   â”œâ”€â”€ processor.py                    # MCP distribution processor
â”‚   â”œâ”€â”€ router.py                       # FastAPI router for MCP endpoints
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ notion.py                   # Notion page creation tool
â”‚       â””â”€â”€ google_calendar.py          # Google Calendar event creation tool
â”œâ”€â”€ api/
â”‚   â””â”€â”€ routes/
â”‚       â””â”€â”€ process.py                  # Manual processing endpoint
â”œâ”€â”€ main.py                             # FastAPI app entry point
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env
```

---

## ðŸš€ Getting Started

### Prerequisites
- **Python** â‰¥ 3.12
- **FFmpeg** installed and available on `PATH`
- **uv** (recommended) or **pip** for dependency management
- **Docker** (for RabbitMQ & MinIO infrastructure)

### Infrastructure Setup

Ensure RabbitMQ and MinIO are running (from the project root):

```bash
docker compose up -d
```

### Installation & Development

```bash
cd ai

# Using uv (recommended)
uv sync
uv run uvicorn main:app --host 0.0.0.0 --port 8000 --reload

# Or using pip
pip install -r requirements.txt
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

The API starts at `http://localhost:8000`.

### Environment Variables

Create a `.env` file in the `ai/` directory:

```env
# LLM Configuration
LLM_PROVIDER=openai          # Options: openai, google, ollama
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=...

# RabbitMQ
RABBITMQ_URL=amqp://admin:admin@localhost:5672

# MinIO
MINIO_ENDPOINT=http://localhost:9000
MINIO_ACCESS_KEY=karim123
MINIO_SECRET_KEY=karim123
MINIO_BUCKET=recordings

# Whisper
WHISPER_MODEL=medium
```

---

## ðŸ”„ Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Extract Audio   â”‚ â”€â”€ Extract audio track from MP4 using FFmpeg
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Clean Audio     â”‚ â”€â”€ Noise reduction & normalization
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transcribe      â”‚ â”€â”€ Whisper speech-to-text (segment-level)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Refine Transcriptâ”‚ â”€â”€ LLM cleans up transcription artifacts
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Summarize       â”‚ â”€â”€ LLM generates structured meeting summary
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚Heuristicâ”‚ â”€â”€ Quick check: does transcript contain events?
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â–¼ Yes    â–¼ No
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ Extract  â”‚  â”‚
â”‚  Events  â”‚  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
     â–¼        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Distribute      â”‚ â”€â”€ Push to Notion & Google Calendar per participant
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Ž Related

- [ðŸ–¥ï¸ Frontend (Video Conferencing UI)](../frontend/README.md)
- [ðŸ“¡ Backend (Signaling & Media Server)](../backend/README.md)
- [ðŸ“˜ Full Project Overview](../README.md)
]]>

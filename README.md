# ğŸš€ WebRTC AI-Powered Meeting Platform

> A full-stack, real-time video conferencing platform with **AI-powered meeting intelligence** â€” featuring live video/audio, chat, composite recording, automatic transcription, summarization, event extraction, and distribution to **Notion** and **Google Calendar**.

---

## ğŸ“– Overview

This project is an end-to-end video conferencing application that combines the power of **WebRTC** (via mediasoup SFU) with an **AI processing pipeline** to transform meetings into actionable outputs. Participants can join rooms, communicate through video, audio, and chat, record meetings, and opt-in to AI features that automatically transcribe, summarize, and extract calendar events from the recording â€” then distribute the results to each participant's connected productivity tools.

---

## ğŸ›ï¸ Architecture

### System Design

![System Design](./system_design.png)

### Backend Flow

![Backend Flow](./backend_flow.png)

### AI Pipelines

![AI Pipelines](./AI_piplines.png)

---

## ğŸ“¦ Project Structure

| Directory | Description | README |
|---|---|---|
| [`frontend/`](./frontend/) | React + TypeScript video conferencing UI | [ğŸ“– Frontend README](./frontend/README.md) |
| [`backend/`](./backend/) | Node.js signaling server, mediasoup SFU, chat, recording | [ğŸ“– Backend README](./backend/README.md) |
| [`ai/`](./ai/) | Python AI pipeline â€” transcription, summarization, distribution | [ğŸ“– AI README](./ai/README.md) |
| `docker-compose.yml` | Infrastructure services (RabbitMQ, MongoDB, MinIO) | â€” |

---

## âœ¨ Key Features

### ğŸ“¹ Real-Time Video Conferencing
- **mediasoup SFU** â€” Scalable Selective Forwarding Unit for multi-party video/audio.
- **Adaptive Video Grid** â€” Dynamic participant layout with camera, mic, and screen sharing controls.
- **Screen Sharing** â€” Full-screen share with other meeting participants.

### ğŸ’¬ In-Meeting Chat
- **Persistent Messages** â€” Chat messages stored in MongoDB with history and pagination.
- **System Notifications** â€” Automatic messages for join/leave and recording events.

### ğŸ¥ Composite Recording
- **Server-Side Recording** â€” All participants combined into a single MP4 via FFmpeg.
- **MinIO Storage** â€” Recordings automatically uploaded to S3-compatible object storage.

### ğŸ¤– AI-Powered Meeting Intelligence
- **Automatic Transcription** â€” Whisper-based speech-to-text with segment-level timestamps.
- **Transcript Refinement** â€” LLM cleans up transcription artifacts for readability.
- **Meeting Summarization** â€” Key points, decisions, and action items extracted by LLM.
- **Calendar Event Extraction** â€” Schedulable follow-ups detected and structured as events.
- **Smart Gating** â€” Heuristic check skips event extraction when not applicable.

### ğŸ”„ Productivity Integration (MCP)
- **Notion** â€” Meeting summaries and transcript pushed to participant's Notion workspace.
- **Google Calendar** â€” Extracted events created as calendar entries.
- **Per-Participant** â€” Each participant independently chooses their integrations.

### ğŸ”— Event-Driven Architecture
- **RabbitMQ** â€” Decoupled backend â†” AI communication via `recording.completed` events.
- **Independent Scaling** â€” Backend and AI services can scale independently.
- **Fault Isolation** â€” AI pipeline failures don't affect the meeting experience.

---

## ğŸ—ï¸ Tech Stack

### Frontend
| Tech | Purpose |
|---|---|
| React 18 + TypeScript | UI framework |
| Vite 5 | Build & dev server |
| mediasoup-client | WebRTC SFU client |
| TailwindCSS | Styling |

### Backend
| Tech | Purpose |
|---|---|
| Node.js + TypeScript | Runtime |
| Express 5 | HTTP API |
| WebSocket (ws) | Real-time signaling |
| mediasoup 3 | SFU media server |
| MongoDB + Mongoose | Data persistence |
| MinIO (AWS SDK v3) | Object storage |
| RabbitMQ (amqplib) | Event messaging |
| FFmpeg | Video recording |

### AI Service
| Tech | Purpose |
|---|---|
| Python 3.12+ | Runtime |
| FastAPI | REST API |
| LangGraph + LangChain | Pipeline orchestration |
| Whisper / WhisperX | Speech-to-text |
| OpenAI / Gemini / Ollama | LLM providers |
| aio-pika | Async RabbitMQ client |
| Notion Client | Notion API |
| Google Calendar API | Calendar integration |

### Infrastructure
| Tech | Purpose |
|---|---|
| RabbitMQ | Message broker |
| MongoDB | Document database |
| MinIO | S3-compatible object storage |
| Docker Compose | Service orchestration |

---

## ğŸš€ Getting Started

### Prerequisites
- **Node.js** â‰¥ 18 with **pnpm**
- **Python** â‰¥ 3.12 with **uv** (or pip)
- **FFmpeg** installed and on `PATH`
- **Docker** & **Docker Compose**
- **Linux / WSL / macOS** (Windows native is not supported due to mediasoup)

### 1. Start Infrastructure

```bash
docker compose up -d
```

This starts **RabbitMQ** (ports 5672, 15672), **MongoDB** (port 27017), and **MinIO** (ports 9000, 9001).

### 2. Start the Backend

```bash
cd backend
pnpm install
pnpm dev
# â†’ Runs on http://localhost:3000
```

### 3. Start the AI Service

```bash
cd ai
uv sync
uv run uvicorn main:app --host 0.0.0.0 --port 8000 --reload
# â†’ Runs on http://localhost:8000
```

### 4. Start the Frontend

```bash
cd frontend/react
pnpm install
pnpm dev
# â†’ Runs on http://localhost:5173
```

### 5. Open the App

Navigate to `http://localhost:5173`, enter a room code and your name, and start your meeting!

---

## ğŸ”„ End-to-End Flow

1. **User joins a room** via the frontend, optionally enabling AI with Notion/Calendar integration tokens.
2. **WebSocket signaling** establishes mediasoup WebRTC transports for bidirectional media.
3. **Video, audio, and chat** flow in real time through the SFU.
4. **Recording starts** â€” the backend captures all participant streams into a composite MP4 via FFmpeg.
5. **Recording stops** â€” the MP4 is uploaded to MinIO, and a `recording.completed` event is published to RabbitMQ.
6. **AI pipeline triggers** â€” the AI service downloads the recording and processes it through the LangGraph pipeline:
   - Extract audio â†’ Clean audio â†’ Transcribe (Whisper) â†’ Refine transcript (LLM) â†’ Summarize (LLM) â†’ Extract events (LLM, conditional) â†’ Distribute
7. **Results distributed** â€” The meeting summary is pushed to each participant's Notion, and extracted events are created in their Google Calendar.

---

## ğŸ“‚ Detailed Documentation

Explore the README for each component:

| Component | Link |
|---|---|
| ğŸ–¥ï¸ **Frontend** â€” React Video Conferencing UI | [Frontend README â†’](./frontend/README.md) |
| ğŸ“¡ **Backend** â€” Signaling, SFU & Recording | [Backend README â†’](./backend/README.md) |
| ğŸ§  **AI Service** â€” Meeting Intelligence Pipeline | [AI README â†’](./ai/README.md) |

---

## ğŸ“„ License

This project is licensed under the **MIT License**.

